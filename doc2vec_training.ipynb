{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Doc2vec Training\n",
    "\n",
    "Install packages to environment.\n",
    "\n",
    "TODO:\n",
    "Run Doc2Vec analysis on sentiment of documents\n",
    "Experiment with incorporating summarization\n",
    "Choose the best Doc2Vec model\n",
    "\n",
    "Testing changes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: gensim in ./venv/lib/python3.6/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./venv/lib/python3.6/site-packages (from gensim) (1.16.1)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./venv/lib/python3.6/site-packages (from gensim) (1.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./venv/lib/python3.6/site-packages (from gensim) (1.2.0)\r\n",
      "Requirement already satisfied: six>=1.5.0 in ./venv/lib/python3.6/site-packages (from gensim) (1.12.0)\r\n",
      "Requirement already satisfied: boto>=2.32 in ./venv/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\r\n",
      "Requirement already satisfied: boto3 in ./venv/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.9.89)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2018.11.29)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./venv/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in ./venv/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./venv/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in ./venv/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.3)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.89 in ./venv/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.89)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in ./venv/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.0)\r\n",
      "Requirement already satisfied: docutils>=0.10 in ./venv/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.89->boto3->smart-open>=1.8.1->gensim) (0.14)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in ./venv/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.89->boto3->smart-open>=1.8.1->gensim) (2.8.0)\r\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting scikit-learn\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/86/764f69d347627f51ceabe46e62990a71a68181469a7773e53b6e4cff30ed/scikit_learn-0.22.1-cp36-cp36m-macosx_10_6_intel.whl (11.1MB)\r\n",
      "\r",
      "\u001b[K     |                                | 10kB 11.2MB/s eta 0:00:01\r",
      "\u001b[K     |                                | 20kB 12.7MB/s eta 0:00:01\r",
      "\u001b[K     |                                | 30kB 2.2MB/s eta 0:00:06\r",
      "\u001b[K     |▏                               | 40kB 2.0MB/s eta 0:00:06\r",
      "\u001b[K     |▏                               | 51kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▏                               | 61kB 1.8MB/s eta 0:00:07\r",
      "\u001b[K     |▏                               | 71kB 1.6MB/s eta 0:00:08\r",
      "\u001b[K     |▎                               | 81kB 1.8MB/s eta 0:00:07\r",
      "\u001b[K     |▎                               | 92kB 1.6MB/s eta 0:00:07\r",
      "\u001b[K     |▎                               | 102kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▎                               | 112kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▍                               | 122kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▍                               | 133kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▍                               | 143kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▍                               | 153kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▌                               | 163kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▌                               | 174kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▌                               | 184kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▋                               | 194kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▋                               | 204kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▋                               | 215kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▋                               | 225kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▊                               | 235kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▊                               | 245kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▊                               | 256kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▊                               | 266kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▉                               | 276kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▉                               | 286kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▉                               | 296kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |▉                               | 307kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 317kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 327kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 337kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 348kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 358kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 368kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█                               | 378kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▏                              | 389kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▏                              | 399kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▏                              | 409kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▏                              | 419kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▎                              | 430kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▎                              | 440kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▎                              | 450kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▎                              | 460kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▍                              | 471kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▍                              | 481kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▍                              | 491kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▌                              | 501kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▌                              | 512kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▌                              | 522kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▌                              | 532kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▋                              | 542kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▋                              | 552kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▋                              | 563kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▋                              | 573kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▊                              | 583kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▊                              | 593kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▊                              | 604kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▊                              | 614kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▉                              | 624kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▉                              | 634kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |█▉                              | 645kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |██                              | 655kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |██                              | 665kB 1.5MB/s eta 0:00:08\r",
      "\u001b[K     |██                              | 675kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██                              | 686kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██                              | 696kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██                              | 706kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██                              | 716kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██                              | 727kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▏                             | 737kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▏                             | 747kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▏                             | 757kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▏                             | 768kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▎                             | 778kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▎                             | 788kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▎                             | 798kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▍                             | 808kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▍                             | 819kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▍                             | 829kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▍                             | 839kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▌                             | 849kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▌                             | 860kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▌                             | 870kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▌                             | 880kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▋                             | 890kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▋                             | 901kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▋                             | 911kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▋                             | 921kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▊                             | 931kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▊                             | 942kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▊                             | 952kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▊                             | 962kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▉                             | 972kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▉                             | 983kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██▉                             | 993kB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███                             | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▏                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▏                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▏                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▏                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▎                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▎                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▎                            | 1.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▍                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▍                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▍                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▍                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▌                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▌                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▌                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▌                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▋                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▋                            | 1.2MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▋                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▋                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▊                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▊                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▊                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▉                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▉                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▉                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |███▉                            | 1.3MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████                            | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▏                           | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▏                           | 1.4MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▏                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▎                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▎                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▎                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▎                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▍                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▍                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▍                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▍                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▌                           | 1.5MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▌                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▌                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▌                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▋                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▋                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▋                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▊                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▊                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▊                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▊                           | 1.6MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▉                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▉                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▉                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |████▉                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.7MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████                           | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▏                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▏                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▏                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▏                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▎                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▎                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▎                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▎                          | 1.8MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▍                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▍                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▍                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▍                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▌                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▌                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▌                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▌                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▋                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▋                          | 1.9MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▋                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▊                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▊                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▊                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▊                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▉                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▉                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▉                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |█████▉                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██████                          | 2.0MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██████                          | 2.1MB 1.5MB/s eta 0:00:07\r",
      "\u001b[K     |██████                          | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 2.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 2.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 2.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 2.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 2.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 2.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 2.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 3.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 3.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 3.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 3.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 3.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 3.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 3.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 4.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 4.2MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 4.3MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 4.4MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 4.5MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 4.6MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 4.7MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.8MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 4.9MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 5.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 5.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 5.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |██████████████▉                 | 5.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |██████████████▉                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████                 | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▏                | 5.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▏                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▏                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▏                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▎                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▎                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▎                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▍                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▍                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▍                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▍                | 5.3MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▌                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▌                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▌                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▌                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▋                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▋                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▋                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▋                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▊                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▊                | 5.4MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▊                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▊                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▉                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▉                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |███████████████▉                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.5MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████                | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▏               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▏               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▏               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▏               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▎               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▎               | 5.6MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▎               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▍               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▍               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▍               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▍               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▌               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▌               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▌               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▌               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▋               | 5.7MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▋               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▋               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▋               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▊               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▊               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▊               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▉               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▉               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▉               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |████████████████▉               | 5.8MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████               | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▏              | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▏              | 5.9MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▏              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▎              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▎              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▎              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▎              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▍              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▍              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▍              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▍              | 6.0MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▌              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▌              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▌              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▌              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▋              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▋              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▋              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▊              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▊              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▊              | 6.1MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▊              | 6.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▉              | 6.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▉              | 6.2MB 1.6MB/s eta 0:00:04\r",
      "\u001b[K     |█████████████████▉              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████▉              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████              | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▏             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▏             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▏             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▎             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▎             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▎             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▎             | 6.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▍             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▍             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▍             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▍             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▌             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▌             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▌             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▌             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▋             | 6.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▋             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▋             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▊             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▊             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▊             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▊             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▉             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▉             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▉             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████▉             | 6.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████             | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▏            | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▏            | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▏            | 6.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▏            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▎            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▎            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▎            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▎            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▍            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▍            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▍            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▍            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▌            | 6.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▌            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▌            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▋            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▋            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▋            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▋            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▊            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▊            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▊            | 6.8MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▊            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▉            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▉            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▉            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████▉            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 6.9MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████            | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▏           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▏           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▏           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▏           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▎           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▎           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▎           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▎           | 7.0MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▍           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▍           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▍           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▌           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▌           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▌           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▌           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▋           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▋           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▋           | 7.1MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▋           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▊           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▊           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▊           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▊           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▉           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▉           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▉           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████▉           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.2MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████           | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▏          | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▏          | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▏          | 7.3MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▏          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▎          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▎          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▎          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▎          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▍          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▍          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▍          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▌          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▌          | 7.4MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▌          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▌          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▋          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▋          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▋          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▋          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▊          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▊          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▊          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▊          | 7.5MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▉          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▉          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████▉          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.6MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████          | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▏         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▏         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▏         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▏         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▎         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▎         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▎         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▍         | 7.7MB 1.6MB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████▍         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▍         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▍         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▌         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▌         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▌         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▌         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▋         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▋         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▋         | 7.8MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▋         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▊         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▊         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▊         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▉         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▉         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▉         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |██████████████████████▉         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 7.9MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████         | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▏        | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▏        | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▏        | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▎        | 8.0MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▎        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▎        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▎        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▍        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▍        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▍        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▍        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▌        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▌        | 8.1MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▌        | 8.2MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▌        | 8.2MB 975kB/s eta 0:00:04\r",
      "\u001b[K     |███████████████████████▋        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▋        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▋        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▋        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▊        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▊        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▊        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▉        | 8.2MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▉        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▉        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |███████████████████████▉        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.3MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████        | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▏       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▏       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▏       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▎       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▎       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▎       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▎       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▍       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▍       | 8.4MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▍       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▍       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▌       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▌       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▌       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▌       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▋       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▋       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▋       | 8.5MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▊       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▊       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▊       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▊       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▉       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▉       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▉       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |████████████████████████▉       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.6MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████       | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▏      | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▏      | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▏      | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▏      | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▎      | 8.7MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▎      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▎      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▎      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▍      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▍      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▍      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▍      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▌      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▌      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▌      | 8.8MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▋      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▋      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▋      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▋      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▊      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▊      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▊      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▊      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▉      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▉      | 8.9MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▉      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |█████████████████████████▉      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████      | 9.0MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▏     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▏     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▏     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▏     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▎     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▎     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▎     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▎     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▍     | 9.1MB 975kB/s eta 0:00:03\r",
      "\u001b[K     |██████████████████████████▍     | 9.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▍     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▍     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▌     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▌     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▌     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▋     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▋     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▋     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▋     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▊     | 9.2MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▊     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▊     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▊     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▉     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▉     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▉     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |██████████████████████████▉     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.3MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████     | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▏    | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▏    | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▏    | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▏    | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▎    | 9.4MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▎    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▎    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▎    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▍    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▍    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▍    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▌    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▌    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▌    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▌    | 9.5MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▋    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▋    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▋    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▋    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▊    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▊    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▊    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▊    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▉    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▉    | 9.6MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |███████████████████████████▉    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████    | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▏   | 9.7MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▏   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▏   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▏   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▎   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▎   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▎   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▍   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▍   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▍   | 9.8MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▍   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▌   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▌   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▌   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▌   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▋   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▋   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▋   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▋   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▊   | 9.9MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▊   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▊   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▊   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▉   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▉   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |████████████████████████████▉   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.0MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████   | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████▏  | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████▏  | 10.1MB 975kB/s eta 0:00:02\r",
      "\u001b[K     |█████████████████████████████▏  | 10.1MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 10.1MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 10.1MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 10.1MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 10.2MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 10.3MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 10.4MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 10.5MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 10.6MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 10.7MB 975kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.7MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 10.8MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 10.9MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 11.0MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 11.1MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 11.1MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 11.1MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 11.1MB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 11.1MB 3.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in ./venv/lib/python3.6/site-packages (from scikit-learn) (1.16.1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in ./venv/lib/python3.6/site-packages (from scikit-learn) (1.2.0)\r\n",
      "Collecting joblib>=0.11 (from scikit-learn)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\r\n",
      "\r",
      "\u001b[K     |█▏                              | 10kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 20kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 30kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 51kB 710kB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 61kB 442kB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 71kB 513kB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 81kB 585kB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 92kB 653kB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 102kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 112kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 122kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 133kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 143kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 153kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 163kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 174kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 184kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 194kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 204kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 215kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 225kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 235kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 245kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 256kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 266kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 276kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 286kB 721kB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 296kB 721kB/s \r\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn\r\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.1\r\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q PyDrive\n",
    "!pip install gensim\n",
    "# Used by Gensim\n",
    "!pip install testfixtures\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following snippet to load article json files from Google Drive. Utility function save_to_drive can be used to save files to Google Drive. Useful for training models in Google Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "1dkWFcIoZoao",
    "outputId": "b528d84e-ab09-4ee3-d09c-fcf1e963dca1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded\n"
     ]
    }
   ],
   "source": [
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# from google.colab import auth\n",
    "# import io\n",
    "# from googleapiclient.http import MediaIoBaseDownload\n",
    "# from googleapiclient.http import MediaFileUpload\n",
    "# \n",
    "# auth.authenticate_user()\n",
    "# from googleapiclient.discovery import build\n",
    "# drive_service = build('drive', 'v3')\n",
    "# \n",
    "# \n",
    "# \n",
    "# files_to_load = list()\n",
    "# \n",
    "# files_to_load.append({\n",
    "#     \"file_name\": \"all_articles.json\",\n",
    "#     \"id\": \"19ErkUdKHwJO46T3u_LnoUhU-Ol4Om90W\",\n",
    "#     \"is_binary\": 0\n",
    "# })\n",
    "# \n",
    "# \n",
    "# def download_from_drive(file_id):\n",
    "# \n",
    "#     request = drive_service.files().get_media(fileId=file_id)\n",
    "#     downloaded = io.BytesIO()\n",
    "#     downloader = MediaIoBaseDownload(downloaded, request)\n",
    "#     done = False\n",
    "#     while done is False:\n",
    "#         # _ is a placeholder for a progress object that we ignore.\n",
    "#         # (Our file is small, so we skip reporting progress.)\n",
    "#         _, done = downloader.next_chunk()\n",
    "# \n",
    "#     downloaded.seek(0)\n",
    "#     read = downloaded.read()\n",
    "#     return read\n",
    "# \n",
    "# \n",
    "# def save_to_drive(filename):\n",
    "# \n",
    "#     file_metadata = {\n",
    "#         'name': filename,\n",
    "#         'mimeType': 'text/plain'\n",
    "#     }\n",
    "#     media = MediaFileUpload(filename,\n",
    "#                             mimetype='text/plain',\n",
    "#                             resumable=True)\n",
    "#     created = drive_service.files().create(body=file_metadata,\n",
    "#                                            media_body=media,\n",
    "#                                            fields='id').execute()\n",
    "#     print('File ID: {}'.format(created.get('id')))\n",
    "# \n",
    "\n",
    "# # Download all the Google Drive files\n",
    "# for file in files_to_load:\n",
    "#     print(file)\n",
    "# \n",
    "#     # load document\n",
    "#     doc = download_from_drive(file[\"id\"])\n",
    "# \n",
    "#     text_file = str()\n",
    "#     if file[\"is_binary\"]:\n",
    "#         text_file = open(file[\"file_name\"], \"wb\")\n",
    "# \n",
    "#     else:\n",
    "#         doc = doc.decode(\"utf-8\")\n",
    "#         text_file = open(file[\"file_name\"], \"w\")\n",
    "# \n",
    "#     text_file.write(doc)\n",
    "#     text_file.close()\n",
    "# \n",
    "#     print(\"loaded: \" + file[\"file_name\"])\n",
    "\n",
    "print(\"Files loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEC4EdY0hAde"
   },
   "source": [
    "## Finding optimal Doc2vec model for IMDB article sentiment prediction\n",
    "\n",
    "Download the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "\n",
    "Load dataset of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents ...\n",
      "Total docs 5000\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import to_unicode\n",
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "random.seed(10)\n",
    "\n",
    "\n",
    "number_of_articles = 5000\n",
    "\n",
    "SentimentDocument = collections.namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "def create_sentiment_document(name, text, index):\n",
    "    \n",
    "    # Split the name of a movie review file into train/test, and +/- sentiment\n",
    "    _, split, sentiment_str, _ = name.split('/')\n",
    "    sentiment = {'pos': 1.0, 'neg': 0.0, 'unsup': None}[sentiment_str]\n",
    "\n",
    "    if sentiment is None:\n",
    "        split = 'extra'\n",
    "\n",
    "    tokens = word_tokenize(to_unicode(text))\n",
    "    return SentimentDocument(tokens, [index], split, sentiment)\n",
    "\n",
    "def extract_documents(imdb_file):\n",
    "    \n",
    "    index = 0\n",
    "\n",
    "    with tarfile.open(imdb_file, mode='r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if re.match(r'aclImdb/(train|test)/(pos|neg|unsup)/\\d+_\\d+.txt$', member.name):\n",
    "                member_bytes = tar.extractfile(member).read()\n",
    "                member_text = member_bytes.decode('utf-8', errors='replace')\n",
    "                assert member_text.count('\\n') == 0\n",
    "                yield create_sentiment_document(member.name, member_text, index)\n",
    "                index += 1\n",
    "                \n",
    "print(\"Loading documents ...\")             \n",
    "alldocs = list(extract_documents('aclImdb_v1.tar.gz'))\n",
    "shuffle(alldocs)\n",
    "alldocs = alldocs[:number_of_articles]\n",
    "\n",
    "print(f\"Total docs {len(alldocs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on the [“Distributed Representations of Sentences and Documents”](http://cs.stanford.edu/~quocle/paragraph_vector.pdf) paper [Radim Hurek's](https://radimrehurek.com/gensim/auto_examples/howtos/run_doc2vec_imdb.html) reproduction of the experiment the `Doc2Vec(dbow,d100,n5,mc2,t8` model produces the lowest error rate in sentiment classification (10.3%).\n",
    "\n",
    "This model is a concatenation of the Distributed Bag of Words model model and the DM/mean model.\n",
    "\n",
    "To analyze whether further preprocessing of the text improves the quality of the embeddings we will train a model model for Text that went through a preprocessing pipeline containing:\n",
    "- Frequency based summarization, lematization, stopword removal, and contraction expansion\n",
    "- Lematization, stopword removal\n",
    "- Contraction expansion, stopword removal\n",
    "- Raw text\n",
    "\n",
    "To evaluate the quality of the embeddings, we will check the accuracy of the sentiment analysis model trained to predict the sentiment based on the document embedding.\n",
    "\n",
    "Define all of the preproccesing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/milanarezina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing Text...\n",
      "Completed Pre-processing\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def substitute_contraction(word):\n",
    "    \"\"\"\n",
    "    Substitutes the contraction with expanded form\n",
    "    Substates non-ascii quotes\n",
    "    :param word:\n",
    "    :return:\n",
    "        The substituted contraction or the original token\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace unicode commas\n",
    "    punctuation = {0x2018: 0x27, 0x2019: 0x27, 0x201C: 0x22, 0x201D: 0x22}\n",
    "    w = word.translate(punctuation)\n",
    "\n",
    "    contractions = get_contraction_dict()\n",
    "\n",
    "    if w in contractions.keys():\n",
    "        subbed = contractions[w]\n",
    "        return subbed\n",
    "    else:\n",
    "        return w\n",
    "    \n",
    "def get_contraction_dict():\n",
    "    return {\n",
    "        \"ain't\": \"is not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he has\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is\",\n",
    "        \"I'd\": \"I would\",\n",
    "        \"I'd've\": \"I would have\",\n",
    "        \"I'll\": \"I will\",\n",
    "        \"I'll've\": \"I shall have\",\n",
    "        \"I'm\": \"I am\",\n",
    "        \"I've\": \"I have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it shall have\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so is\",\n",
    "        \"that'd\": \"that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"there'd\": \"there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is\",\n",
    "        \"they'd\": \"they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "\n",
    "class LanguageProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        All of the natural processing functionality\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        self.punctuation_list = [c for c in punctuation]\n",
    "        \n",
    "        self.STOPWORDS = stopwords.words()\n",
    "\n",
    "        # TODO: Get more complete list and read it from file\n",
    "        MORESTOP = ['will', 'thing', 'n\\'t', '\\'\\'', '\\'s', '``', '\\'re', '\\'', 'mr', 'mr.', '--', '...', '..', '->', '\\'.',\n",
    "                    '\\' \\'', ' .', '’',\n",
    "                    '“', '”', \"\", \"\\n\"]\n",
    "        self.STOPWORDS.extend(MORESTOP)\n",
    "\n",
    "    def substitute_contractions(self, words):\n",
    "        \"\"\"\n",
    "        Loop through words and sub contractions\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        subbed = []\n",
    "        for word in words:\n",
    "            subbed.append(substitute_contraction(word))\n",
    "        return subbed\n",
    "\n",
    "    def get_non_stopwords(self, words, substitute_contractions=True, stem=True):\n",
    "        \"\"\"\n",
    "        Returns a list of lowercase non-stopwords in the text.\n",
    "        non-stopwords are anything that is not punctuation or stopwords\n",
    "        Numerical values are NOT FILTERED OUT\n",
    "        :param text:\n",
    "        :param stem:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if substitute_contractions:\n",
    "            words = self.substitute_contractions(words)\n",
    "\n",
    "        non_stop_words = []\n",
    "\n",
    "        # Loop through tokens\n",
    "        for word in words:\n",
    "            token = self.remove_punctuation(word.lower())\n",
    "            if token not in self.STOPWORDS:\n",
    "                # Check if token contains punctuation\n",
    "                if token not in self.punctuation_list:\n",
    "                    if stem:\n",
    "                        non_stop_words.append(self.get_word_lemma(token))\n",
    "                    else:\n",
    "                        non_stop_words.append(token)\n",
    "\n",
    "        return non_stop_words\n",
    "    \n",
    "\n",
    "    def get_word_lemma(self, word):\n",
    "        \"\"\"\n",
    "        Helper to allows customization to stemming process, like checking for trailing e's\n",
    "        :param word:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        lema = self.lemmatizer.lemmatize(word)\n",
    "        return lema\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        \"\"\"\n",
    "        Helper function to remove all non-acsii charcters\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "    def is_text_token(self, token):\n",
    "        \"\"\"\n",
    "        Checks if not punc or numerical, or non-acsii\n",
    "        :param token:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if len(token) == 1:\n",
    "            if ord(token) < 128 and token not in punctuation and not token.isdigit():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            if not token.isdigit():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    \n",
    "# Perform each type of preprocesing\n",
    "# TODO: Add \"sum+lem+stop+con\"\n",
    "corpora = [\"lem+stop+con\", \"stop+con\", \"stop\", \"none\"]\n",
    "processed_texts = {cor:[] for cor in corpora}\n",
    "processor = LanguageProcessor()\n",
    "\n",
    "print(\"Pre-processing Text...\")\n",
    "\n",
    "# lem+stop+con\n",
    "for doc in alldocs:\n",
    "    words = processor.get_non_stopwords(doc.words, substitute_contractions=True, stem=True)\n",
    "    doc2 = SentimentDocument(words, doc.tags, doc.split, doc.sentiment)\n",
    "    processed_texts[\"lem+stop+con\"].append(doc2)\n",
    "    \n",
    "# stop+con\n",
    "for doc in alldocs:\n",
    "    words = processor.get_non_stopwords(doc.words, substitute_contractions=True, stem=False)\n",
    "    doc2 = SentimentDocument(words, doc.tags, doc.split, doc.sentiment)\n",
    "    processed_texts[\"stop+con\"].append(doc2)\n",
    "    \n",
    "# stop\n",
    "for doc in alldocs:\n",
    "    words = processor.get_non_stopwords(doc.words, substitute_contractions=False, stem=False)\n",
    "    doc2 = SentimentDocument(words, doc.tags, doc.split, doc.sentiment)\n",
    "    processed_texts[\"stop\"].append(doc2)\n",
    "\n",
    "processed_texts[\"none\"] = alldocs\n",
    "\n",
    "print(\"Completed Pre-processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start training a model for each of the types of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / test data breakdown./n\n",
      "       Train + samples 634 out of 1216\n",
      "       Test + samples 605 out of 1236\n",
      "Training Doc2Vec models ...\n",
      "Sample Data [array([ 5.6732041e-01, -1.5045159e-01, -1.3404600e-01,  1.3722098e-01,\n",
      "        4.9046463e-01, -9.5677972e-02,  5.1298159e-01,  1.9984940e-01,\n",
      "        3.3094478e-01,  2.4243297e-01, -3.2563621e-01,  7.6364234e-02,\n",
      "        7.7105887e-02,  6.7370757e-02,  6.9363117e-02, -2.1065657e-01,\n",
      "       -1.4787093e-01, -4.2737238e-02, -3.1358701e-01,  9.0477049e-02,\n",
      "       -2.5931928e-01, -1.1857605e-01, -4.7702368e-02,  7.3139243e-02,\n",
      "        5.2795416e-01, -8.7012313e-03, -4.7693051e-02, -4.1566485e-01,\n",
      "        4.2422578e-01,  5.3356123e-01,  4.9205843e-02, -4.7729787e-01,\n",
      "        5.9970427e-01, -1.7768775e-01, -2.0582248e-01,  3.4385812e-01,\n",
      "        1.8806180e-02,  4.7904956e-01, -6.2647216e-02, -3.8395859e-02,\n",
      "       -4.4655764e-01,  8.3381750e-02, -1.3778973e-02, -3.3397365e-02,\n",
      "       -5.8208238e-02, -2.0586295e-01, -2.5060996e-01, -4.8069075e-01,\n",
      "       -6.3281035e-04,  9.7013354e-02, -7.6953851e-02,  9.7184524e-02,\n",
      "        4.7632816e-01, -8.9117473e-01, -1.1385083e-01, -4.0840086e-01,\n",
      "       -6.0748333e-01, -2.4011080e-01,  7.3500991e-02, -6.0849953e-01,\n",
      "       -2.4706051e-01,  6.9844741e-03,  9.5811538e-02, -2.3783755e-01,\n",
      "       -5.8926606e-01,  2.0684832e-01, -5.4212388e-02, -2.5158870e-01,\n",
      "        5.7972658e-01,  2.4336560e-01, -6.5088272e-02,  2.0953972e-02,\n",
      "        1.1341417e-01,  2.6926979e-01,  3.0371881e-01, -2.2733349e-01,\n",
      "       -6.6706479e-02,  1.8579714e-01, -1.7970586e-01, -4.4399068e-02,\n",
      "       -2.3798949e-01, -4.0862331e-01,  1.4564531e-01,  1.4210241e-01,\n",
      "        5.2684162e-02, -1.0791460e-01,  5.0723232e-02,  1.1701871e-01,\n",
      "       -2.4468091e-01,  3.8178119e-01, -2.7525955e-01, -1.4034684e-01,\n",
      "       -2.4463688e-01, -1.0188476e-01, -2.2256227e-01, -1.7461902e-01,\n",
      "       -2.0669748e-01,  3.2956940e-01, -2.5397682e-01,  4.5537433e-01],\n",
      "      dtype=float32)] [1.0]\n",
      "Error rate: 0.1796116504854369 for model Doc2Vec(dbow,d100,n5,mc2,t4) trained on lem+stop+con\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data [array([ 0.5592159 , -0.2124945 , -0.11359403, -0.07989923,  0.493046  ,\n",
      "        0.04332501,  0.53577256,  0.1539192 ,  0.42575216,  0.35212165,\n",
      "       -0.46236637, -0.09379772,  0.19456255,  0.14521497, -0.2001808 ,\n",
      "       -0.25263897, -0.3740594 , -0.07511456, -0.13910925,  0.16933969,\n",
      "       -0.29688412,  0.0370101 ,  0.12812383,  0.16704799,  0.38220295,\n",
      "        0.09815471, -0.10323657, -0.40888742,  0.4937175 ,  0.5472012 ,\n",
      "       -0.1141421 , -0.30166584,  0.50648654,  0.02521893, -0.09819523,\n",
      "        0.1995767 ,  0.12520148,  0.30192897, -0.15562509, -0.10434534,\n",
      "       -0.3164872 , -0.26827303,  0.12724707,  0.18881716, -0.16650757,\n",
      "       -0.2234285 , -0.31902844, -0.08764739, -0.08660065,  0.11887589,\n",
      "       -0.0444833 ,  0.4833364 ,  0.42072552, -0.6550969 ,  0.05436633,\n",
      "       -0.19142646, -0.69783443, -0.3281721 , -0.07723249, -0.68224597,\n",
      "       -0.41878676, -0.15308873, -0.19469215,  0.01088935, -0.47998303,\n",
      "        0.1665273 , -0.01943147, -0.12742233,  0.5408349 ,  0.36069137,\n",
      "       -0.03326175,  0.11430734, -0.01940759,  0.13524836,  0.37115782,\n",
      "        0.12888157, -0.24268062,  0.10484473, -0.26558033, -0.00242252,\n",
      "       -0.23425673, -0.559318  ,  0.033438  ,  0.16768414, -0.00297126,\n",
      "        0.07825983,  0.05563165,  0.02683136, -0.32308686,  0.22985691,\n",
      "       -0.11270189, -0.34940118,  0.05020111, -0.2681315 , -0.44296598,\n",
      "       -0.14439599, -0.19584985,  0.35789979, -0.36795282,  0.55034226],\n",
      "      dtype=float32)] [1.0]\n",
      "Error rate: 0.1820388349514563 for model Doc2Vec(dbow,d100,n5,mc2,t4) trained on stop+con\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data [array([ 3.89284551e-01, -1.90338150e-01, -2.22841114e-01, -2.75844727e-02,\n",
      "        5.41346490e-01,  2.20858417e-02,  2.92208016e-01,  2.05596656e-01,\n",
      "        2.13889420e-01,  3.25156778e-01, -3.69208455e-01,  1.81449354e-01,\n",
      "        9.47325528e-02,  1.14872798e-01, -1.29874468e-01, -3.03048730e-01,\n",
      "       -2.35848173e-01, -1.22107446e-01, -3.55402321e-01, -6.00956716e-02,\n",
      "       -4.05965537e-01,  8.91375095e-02, -1.03781983e-01,  1.97665617e-02,\n",
      "        3.53688002e-01,  4.99986932e-02,  2.03840341e-02, -3.05211902e-01,\n",
      "        3.26379806e-01,  5.83029449e-01,  1.78342331e-02, -4.67134982e-01,\n",
      "        5.09939015e-01, -7.43062124e-02,  1.00376152e-01,  3.36861640e-01,\n",
      "        1.14539601e-01,  4.62570339e-01, -1.43052742e-01, -1.84383556e-01,\n",
      "       -4.53279793e-01, -8.66451710e-02,  1.29543364e-01,  2.39633456e-01,\n",
      "       -3.11237514e-01, -3.33522648e-01, -3.45800787e-01, -5.36273122e-02,\n",
      "        3.85828689e-02,  3.83421667e-02, -1.40179574e-01,  4.29554760e-01,\n",
      "        4.61749732e-01, -6.36470854e-01, -1.25277057e-01, -2.81020105e-01,\n",
      "       -6.34428740e-01, -8.34691674e-02, -5.96059486e-04, -4.92669731e-01,\n",
      "       -3.00392389e-01,  2.83271540e-02,  1.78140141e-02, -1.70203909e-01,\n",
      "       -4.00991499e-01,  6.63792342e-02, -3.44995819e-02, -2.15374112e-01,\n",
      "        6.35330915e-01,  2.54886478e-01, -2.84962915e-02,  5.71775660e-02,\n",
      "        4.36694808e-02,  5.36466390e-02,  4.52816159e-01, -5.26332557e-02,\n",
      "       -2.26364225e-01,  3.76806319e-01, -4.16015744e-01, -7.71565884e-02,\n",
      "       -3.83344114e-01, -5.00244915e-01,  1.41105771e-01,  1.69285476e-01,\n",
      "        8.02900195e-02,  3.82096507e-02, -4.65384871e-02,  5.81814162e-03,\n",
      "       -1.70887008e-01,  3.21484059e-01, -3.52634221e-01, -2.19896376e-01,\n",
      "        4.04919237e-02, -1.20593287e-01, -4.61824328e-01, -1.99545771e-01,\n",
      "       -2.23487586e-01,  4.82763648e-01, -2.46360555e-01,  7.34574258e-01],\n",
      "      dtype=float32)] [1.0]\n",
      "Error rate: 0.18284789644012944 for model Doc2Vec(dbow,d100,n5,mc2,t4) trained on stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data [array([ 0.7376561 ,  0.17932598,  0.2611437 , -0.32239255,  0.09196929,\n",
      "        0.29507193,  0.37854517,  0.00339886, -0.01398464,  0.33527923,\n",
      "        0.12992382, -0.0793631 ,  0.04529709,  0.6470843 ,  0.00678122,\n",
      "        1.0538138 ,  0.1896606 ,  0.44365433,  0.02904843, -0.37472034,\n",
      "        0.5362853 , -0.02225481,  0.11684397,  0.328072  ,  0.70614606,\n",
      "       -0.02710428,  0.06597864,  0.32214817,  0.13743596,  0.34960157,\n",
      "        0.2457095 , -0.6687889 , -0.5138187 , -0.3267631 ,  0.01713321,\n",
      "       -0.1381212 , -0.0374371 , -0.12914641, -0.46013403, -0.37928903,\n",
      "        0.3442215 , -0.52603734, -0.55528045, -0.4130225 , -0.11150237,\n",
      "       -0.05974048,  0.5230761 , -0.5556463 , -0.06862046,  0.6689113 ,\n",
      "       -0.5924819 ,  0.06163547, -0.0566548 , -0.14699143,  0.12596385,\n",
      "       -0.03447998, -0.41865787,  0.3632839 , -0.31997642,  0.5263574 ,\n",
      "        0.11189838, -0.15244666,  0.8590168 ,  0.74061275,  0.24557051,\n",
      "        0.18393807, -0.51347893,  0.15955116,  0.10027259, -0.5942713 ,\n",
      "       -0.05929174,  0.33709967, -0.20205966,  0.6024044 ,  0.27841944,\n",
      "        0.08593255,  0.07172917, -0.4141499 ,  0.31704387,  0.19802098,\n",
      "       -0.3005738 , -0.41052705,  0.00771788,  0.69826216, -0.1152007 ,\n",
      "       -0.15555488,  0.03520637, -0.0820901 , -0.5005058 ,  0.9989417 ,\n",
      "       -0.21068995, -0.490043  ,  0.31625444, -0.27014405, -0.08996801,\n",
      "        0.5735559 ,  0.25948998, -0.40217546, -0.09452949,  0.97063696],\n",
      "      dtype=float32)] [1.0]\n",
      "Error rate: 0.18608414239482202 for model Doc2Vec(dbow,d100,n5,mc2,t4) trained on none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "# Keep track of the error rates for each model\n",
    "error_rates = {}\n",
    "\n",
    "def logistic_regression_predictor(X, y):\n",
    "    \"\"\"\n",
    "    Return the predictor after fitting a model on embeddings and sentiment class\n",
    "    :param X: \n",
    "        Embeddings\n",
    "    :param y: \n",
    "        Sentiment class\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(random_state=0, verbose=True).fit(X, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def model_error_rate(doc2vec_model, train, test):\n",
    "    \"\"\"\n",
    "    Test error rate of regression model that uses the doc2vec embeddings to predict sentiment class\n",
    "    :param doc2vec_model: \n",
    "    :param train: \n",
    "    :param test: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    train_y = [doc.sentiment for doc in train_docs]\n",
    "    train_x = [doc2vec_model.docvecs[doc.tags[0]] for doc in train_docs]\n",
    "    test_x = [doc2vec_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "\n",
    "    print(\"Sample Data\", train_x[:1], train_y[:1])\n",
    "    \n",
    "    predictor = logistic_regression_predictor(train_x, train_y)\n",
    "    test_predictions = predictor.predict(test_x)\n",
    "\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    \n",
    "    return error_rate, errors, len(test_predictions), predictor\n",
    "    \n",
    "\n",
    "    \n",
    "print(f\"\"\"Train / test data breakdown./n\n",
    "       Train + samples {[doc.sentiment for doc in alldocs if doc.split == 'train'].count(1.0)} out of {len(train_docs)}\n",
    "       Test + samples {[doc.sentiment for doc in alldocs if doc.split == 'test'].count(1.0)} out of {len(test_docs)}\"\"\")\n",
    "    \n",
    "\n",
    "# Common Doc2vec configuration\n",
    "common_kwargs = dict(\n",
    "    vector_size=100, epochs=20, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Doc2vec models for each type of preproccesing\n",
    "models_by_corpora = {}\n",
    "for model in corpora:\n",
    "    \n",
    "    # TODO: Concatenated doc2vec model perform slightly better, however it is missing\n",
    "    # tags property in it's implementation.\n",
    "    # 2nd best model used\n",
    "    models_by_corpora[model] = Doc2Vec(dm=0, **common_kwargs)\n",
    "    \n",
    "    \n",
    "print(\"Training Doc2Vec models ...\")\n",
    "\n",
    "# Evaluate Doc2vec for each type of preproccesing\n",
    "for corpus in corpora:\n",
    "    \n",
    "    model = models_by_corpora[corpus]\n",
    "    docs = processed_texts[corpus]\n",
    "    \n",
    "    # Split into train / test sets\n",
    "    train_docs = [doc for doc in docs if doc.split == 'train']\n",
    "    test_docs = [doc for doc in docs if doc.split == 'test']\n",
    "    \n",
    "    model.build_vocab(docs)\n",
    "    model.train(docs, total_examples=len(docs), epochs=model.epochs)\n",
    "\n",
    "    err_rate, err_count, test_count, predictor = model_error_rate(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(f\"Error rate: {err_rate} for model {str(model)} trained on {corpus}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training documents 21\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "article_dataset = \"harvard_articles.json\"\n",
    "# Save file for Doc2Vec model (pickle)\n",
    "save_file = \"health_doc2vec\"\n",
    "\n",
    "\n",
    "content = json.load(open(article_dataset, 'r'))\n",
    "article_list = [con[\"text\"] for con in content]\n",
    "\n",
    "print(\"Total training documents {0}\".format(len(article_list)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9_9Gcz9aaEAr",
    "outputId": "a07ae9db-83c7-40cf-f7fc-9b68d50e6aed",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not connect to 127.0.0.1: 56556\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydevd_bundle/pydevd_comm.py\", line 449, in start_client\n",
      "    s.connect((host, port))\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/PyCharm.app/Contents/helpers-pro/jupyter_debug/pydev_jupyter_utils.py\", line 68, in attach_to_debugger\n",
      "    debugger.connect(pydev_localhost.get_localhost(), debugger_port)\n",
      "  File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py\", line 596, in connect\n",
      "    s = start_client(host, port)\n",
      "  File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydevd_bundle/pydevd_comm.py\", line 449, in start_client\n",
      "    s.connect((host, port))\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "Failed to connect to target debugger.\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def substitute_contraction(word):\n",
    "    \"\"\"\n",
    "    Substitutes the contraction with expanded form\n",
    "    Substates non-ascii quotes\n",
    "    :param word:\n",
    "    :return:\n",
    "        The substituted contraction or the original token\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace unicode commas\n",
    "    punctuation = {0x2018: 0x27, 0x2019: 0x27, 0x201C: 0x22, 0x201D: 0x22}\n",
    "    w = word.translate(punctuation)\n",
    "\n",
    "    contractions = get_contraction_dict()\n",
    "\n",
    "    if w in contractions.keys():\n",
    "        subbed = contractions[w]\n",
    "        return subbed\n",
    "    else:\n",
    "        return w\n",
    "\n",
    "\n",
    "def get_contraction_dict():\n",
    "    return {\n",
    "        \"ain't\": \"is not\",\n",
    "        \"aren't\": \"are not\",\n",
    "        \"can't\": \"cannot\",\n",
    "        \"can't've\": \"cannot have\",\n",
    "        \"'cause\": \"because\",\n",
    "        \"could've\": \"could have\",\n",
    "        \"couldn't\": \"could not\",\n",
    "        \"couldn't've\": \"could not have\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"doesn't\": \"does not\",\n",
    "        \"don't\": \"do not\",\n",
    "        \"hadn't\": \"had not\",\n",
    "        \"hadn't've\": \"had not have\",\n",
    "        \"hasn't\": \"has not\",\n",
    "        \"haven't\": \"have not\",\n",
    "        \"he'd\": \"he would\",\n",
    "        \"he'd've\": \"he would have\",\n",
    "        \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\",\n",
    "        \"he's\": \"he has\",\n",
    "        \"how'd\": \"how did\",\n",
    "        \"how'd'y\": \"how do you\",\n",
    "        \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is\",\n",
    "        \"I'd\": \"I would\",\n",
    "        \"I'd've\": \"I would have\",\n",
    "        \"I'll\": \"I will\",\n",
    "        \"I'll've\": \"I shall have\",\n",
    "        \"I'm\": \"I am\",\n",
    "        \"I've\": \"I have\",\n",
    "        \"isn't\": \"is not\",\n",
    "        \"it'd\": \"it would\",\n",
    "        \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\",\n",
    "        \"it'll've\": \"it shall have\",\n",
    "        \"it's\": \"it is\",\n",
    "        \"let's\": \"let us\",\n",
    "        \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\",\n",
    "        \"might've\": \"might have\",\n",
    "        \"mightn't\": \"might not\",\n",
    "        \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\",\n",
    "        \"mustn't\": \"must not\",\n",
    "        \"mustn't've\": \"must not have\",\n",
    "        \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\",\n",
    "        \"o'clock\": \"of the clock\",\n",
    "        \"oughtn't\": \"ought not\",\n",
    "        \"oughtn't've\": \"ought not have\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\",\n",
    "        \"shan't've\": \"shall not have\",\n",
    "        \"she'd\": \"she would\",\n",
    "        \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\",\n",
    "        \"she'll've\": \"she will have\",\n",
    "        \"she's\": \"she is\",\n",
    "        \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\",\n",
    "        \"shouldn't've\": \"should not have\",\n",
    "        \"so've\": \"so have\",\n",
    "        \"so's\": \"so is\",\n",
    "        \"that'd\": \"that had\",\n",
    "        \"that'd've\": \"that would have\",\n",
    "        \"that's\": \"that is\",\n",
    "        \"there'd\": \"there would\",\n",
    "        \"there'd've\": \"there would have\",\n",
    "        \"there's\": \"there is\",\n",
    "        \"they'd\": \"they would\",\n",
    "        \"they'd've\": \"they would have\",\n",
    "        \"they'll\": \"they will\",\n",
    "        \"they'll've\": \"they will have\",\n",
    "        \"they're\": \"they are\",\n",
    "        \"they've\": \"they have\",\n",
    "        \"to've\": \"to have\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'd\": \"we would\",\n",
    "        \"we'd've\": \"we would have\",\n",
    "        \"we'll\": \"we will\",\n",
    "        \"we'll've\": \"we will have\",\n",
    "        \"we're\": \"we are\",\n",
    "        \"we've\": \"we have\",\n",
    "        \"weren't\": \"were not\",\n",
    "        \"what'll\": \"what will\",\n",
    "        \"what'll've\": \"what will have\",\n",
    "        \"what're\": \"what are\",\n",
    "        \"what's\": \"what is\",\n",
    "        \"what've\": \"what have\",\n",
    "        \"when's\": \"when is\",\n",
    "        \"when've\": \"when have\",\n",
    "        \"where'd\": \"where did\",\n",
    "        \"where's\": \"where is\",\n",
    "        \"where've\": \"where have\",\n",
    "        \"who'll\": \"who will\",\n",
    "        \"who'll've\": \"who will have\",\n",
    "        \"who's\": \"who is\",\n",
    "        \"who've\": \"who have\",\n",
    "        \"why's\": \"why is\",\n",
    "        \"why've\": \"why have\",\n",
    "        \"will've\": \"will have\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"won't've\": \"will not have\",\n",
    "        \"would've\": \"would have\",\n",
    "        \"wouldn't\": \"would not\",\n",
    "        \"wouldn't've\": \"would not have\",\n",
    "        \"y'all\": \"you all\",\n",
    "        \"y'all'd\": \"you all would\",\n",
    "        \"y'all'd've\": \"you all would have\",\n",
    "        \"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\n",
    "        \"you'd\": \"you would\",\n",
    "        \"you'd've\": \"you would have\",\n",
    "        \"you'll\": \"you will\",\n",
    "        \"you'll've\": \"you will have\",\n",
    "        \"you're\": \"you are\",\n",
    "        \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "class LanguageProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        All of the natural processing functionality\n",
    "        \"\"\"\n",
    "\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        self.punctuation_list = [c for c in punctuation]\n",
    "\n",
    "        self.STOPWORDS = [' .', \"'\", \"' '\", \"''\", \"'.\", \"'ll\", \"'re\", \"'s\", \"'ve\", '--', '->', '..', '...', '``', 'a', \"a's\",\n",
    "                     'able',\n",
    "                     'about', 'above', 'abst', 'accordance', 'according', 'accordingly', 'across', 'act', 'actually',\n",
    "                     'added',\n",
    "                     'adj', 'affected', 'affecting', 'affects', 'after', 'afterwards', 'again', 'against', 'ah',\n",
    "                     \"ain't\", 'all',\n",
    "                     'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am',\n",
    "                     'among',\n",
    "                     'amongst', 'an', 'and', 'announce', 'another', 'any', 'anybody', 'anyhow', 'anymore', 'anyone',\n",
    "                     'anything',\n",
    "                     'anyway', 'anyways', 'anywhere', 'apart', 'apparently', 'appear', 'appreciate', 'appropriate',\n",
    "                     'approximately', 'are', 'area', 'areas', 'aren', \"aren't\", 'arent', 'arise', 'around', 'as',\n",
    "                     'aside',\n",
    "                     'ask', 'asked', 'asking', 'asks', 'associated', 'at', 'auth', 'available', 'away', 'awfully', 'b',\n",
    "                     'back',\n",
    "                     'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been',\n",
    "                     'before',\n",
    "                     'beforehand', 'began', 'begin', 'beginning', 'beginnings', 'begins', 'behind', 'being', 'beings',\n",
    "                     'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'big', 'biol',\n",
    "                     'both',\n",
    "                     'brief', 'briefly', 'but', 'by', 'c', \"c'mon\", \"c's\", 'ca', 'came', 'campaign', 'can', \"can't\",\n",
    "                     'cannot',\n",
    "                     'cant', 'case', 'cases', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clear', 'clearly',\n",
    "                     'co',\n",
    "                     'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain',\n",
    "                     'containing',\n",
    "                     'contains', 'corresponding', 'could', \"couldn't\", 'couldnt', 'course', 'criticized', 'have',\n",
    "                     'currently',\n",
    "                     'd', 'date', 'definitely', 'described', 'despite', 'did', \"didn't\", 'differ', 'different',\n",
    "                     'differently',\n",
    "                     'do', 'does', \"doesn't\", 'doing', \"don't\", 'done', 'down', 'downed', 'downing', 'downs',\n",
    "                     'downwards',\n",
    "                     'due', 'during', 'e', 'each', 'early', 'ed', 'edu', 'effect', 'eg', 'eight', 'eighty', 'either',\n",
    "                     'else',\n",
    "                     'elsewhere', 'end', 'ended', 'ending', 'endorsed', 'ends', 'enough', 'entirely', 'especially',\n",
    "                     'et',\n",
    "                     'et-al', 'etc', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything',\n",
    "                     'everywhere',\n",
    "                     'ex', 'exactly', 'example', 'except', 'f', 'face', 'faces', 'fact', 'facts', 'far', 'felt', 'few',\n",
    "                     'ff',\n",
    "                     'fifth', 'financial', 'find', 'finds', 'first', 'five', 'fix', 'followed', 'following', 'follows',\n",
    "                     'for',\n",
    "                     'former', 'formerly', 'forth', 'found', 'four', 'from', 'full', 'fully', 'further', 'furthered',\n",
    "                     'furthering', 'furthermore', 'furthers', 'g', 'gave', 'general', 'generally', 'get', 'gets',\n",
    "                     'getting',\n",
    "                     'give', 'given', 'gives', 'giving', 'go', 'goes', 'going', 'gone', 'good', 'goods', 'got',\n",
    "                     'gotten',\n",
    "                     'great', 'greater', 'greatest', 'greetings', 'group', 'grouped', 'grouping', 'groups', 'h', 'had',\n",
    "                     \"hadn't\", 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he's\", 'hed',\n",
    "                     'hello',\n",
    "                     'help', 'hence', 'her', 'here', \"here's\", 'hereafter', 'hereby', 'herein', 'heres', 'hereupon',\n",
    "                     'hers',\n",
    "                     'herself', 'hes', 'hi', 'hid', 'high', 'higher', 'highest', 'him', 'himself', 'his', 'hither',\n",
    "                     'home',\n",
    "                     'hopefully', 'how', 'howbeit', 'however', 'hundred', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'id', 'ie',\n",
    "                     'if',\n",
    "                     'ignored', 'im', 'immediate', 'immediately', 'importance', 'important', 'in', 'inasmuch', 'inc',\n",
    "                     'indeed',\n",
    "                     'index', 'indicate', 'indicated', 'indicates', 'information', 'inner', 'insofar', 'instead',\n",
    "                     'interest',\n",
    "                     'interested', 'interesting', 'interests', 'into', 'invention', 'inward', 'is', \"isn't\", 'it',\n",
    "                     \"it'd\",\n",
    "                     \"it'll\", \"it's\", 'itd', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keep', 'keeps', 'kept', 'kg',\n",
    "                     'kind',\n",
    "                     'km', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', 'last', 'lately', 'later',\n",
    "                     'latest',\n",
    "                     'latter', 'latterly', 'least', 'less', 'lest', 'let', \"let's\", 'lets', 'like', 'liked', 'likely',\n",
    "                     'line',\n",
    "                     'little', 'long', 'longer', 'longest', 'look', 'looking', 'looks', 'ltd', 'm', 'made', 'mainly',\n",
    "                     'make',\n",
    "                     'makes', 'making', 'man', 'many', 'may', 'maybe', 'me', 'mean', 'means', 'meantime', 'meanwhile',\n",
    "                     'member',\n",
    "                     'members', 'men', 'merely', 'mg', 'might', 'million', 'miss', 'ml', 'more', 'moreover', 'most',\n",
    "                     'mostly',\n",
    "                     'mr', 'mr.', 'mrs', 'much', 'mug', 'must', 'my', 'myself', 'n', \"n't\", 'na', 'name', 'namely',\n",
    "                     'nay', 'nd',\n",
    "                     'near', 'nearly', 'necessarily', 'necessary', 'need', 'needed', 'needing', 'needs', 'neither',\n",
    "                     'never',\n",
    "                     'nevertheless', 'new', 'newer', 'newest', 'next', 'nine', 'ninety', 'no', 'nobody', 'non', 'none',\n",
    "                     'nonetheless', 'noone', 'nor', 'normally', 'nos', 'not', 'noted', 'nothing', 'novel', 'now',\n",
    "                     'nowhere',\n",
    "                     'number', 'numbered', 'numbering', 'numbers', 'o', 'obtain', 'obtained', 'obviously', 'of', 'off',\n",
    "                     'official', 'often', 'oh', 'ok', 'okay', 'old', 'older', 'oldest', 'omitted', 'on', 'once', 'one',\n",
    "                     'ones',\n",
    "                     'only', 'onto', 'open', 'opened', 'opening', 'opens', 'or', 'ord', 'order', 'ordered', 'ordering',\n",
    "                     'orders', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside',\n",
    "                     'over',\n",
    "                     'overall', 'owing', 'own', 'p', 'page', 'pages', 'part', 'parted', 'particular', 'particularly',\n",
    "                     'parting',\n",
    "                     'parts', 'past', 'per', 'perhaps', 'place', 'placed', 'places', 'please', 'plus', 'point',\n",
    "                     'pointed',\n",
    "                     'pointing', 'points', 'poorly', 'possible', 'possibly', 'potentially', 'pp', 'predominantly',\n",
    "                     'present',\n",
    "                     'presented', 'presenting', 'presents', 'presumably', 'previously', 'primarily', 'probably',\n",
    "                     'problem',\n",
    "                     'problems', 'promptly', 'proud', 'provides', 'put', 'puts', 'q', 'quarterly', 'que', 'quickly',\n",
    "                     'quite',\n",
    "                     'quote', 'qv', 'r', 'ran', 'rather', 'rd', 're', 'readily', 'really', 'reasonably', 'recent',\n",
    "                     'recently',\n",
    "                     'ref', 'refs', 'regarding', 'regardless', 'regards', 'relatively', 'related', 'relatively',\n",
    "                     'research',\n",
    "                     'respectively', 'resulted', 'resulting', 'results', 'right', 'room', 'rooms', 'run', 's', 'said',\n",
    "                     'same',\n",
    "                     'saw', 'say', 'saying', 'says', 'sec', 'second', 'secondly', 'seconds', 'section', 'see', 'seeing',\n",
    "                     'seem',\n",
    "                     'seemed', 'seeming', 'seems', 'seen', 'sees', 'self', 'selves', 'sensible', 'sent', 'serious',\n",
    "                     'seriously',\n",
    "                     'seven', 'several', 'shall', 'sharply', 'she', \"she'll\", 'shed', 'shes', 'should', \"shouldn't\",\n",
    "                     'show',\n",
    "                     'showed', 'showing', 'shown', 'showns', 'shows', 'side', 'sides', 'significant', 'significantly',\n",
    "                     'similar', 'similarly', 'since', 'six', 'slightly', 'small', 'smaller', 'smallest', 'so', 'some',\n",
    "                     'somebody', 'somehow', 'someone', 'somethan', 'something', 'sometime', 'sometimes', 'somewhat',\n",
    "                     'somewhere', 'soon', 'sorry', 'specifically', 'specified', 'specify', 'specifying', 'state',\n",
    "                     'states',\n",
    "                     'still', 'stop', 'strongly', 'sub', 'substantially', 'successfully', 'such', 'sufficiently',\n",
    "                     'suggest',\n",
    "                     'sup', 'sure', 'sure', 't', \"t's\", 'take', 'taken', 'taking', 'tell', 'tends', 'th', 'than',\n",
    "                     'thank',\n",
    "                     'thanks', 'thanx', 'that', \"that'll\", \"that's\", \"that've\", 'thats', 'the', 'their', 'theirs',\n",
    "                     'them',\n",
    "                     'themselves', 'then', 'thence', 'there', \"there'll\", \"there's\", \"there've\", 'thereafter',\n",
    "                     'thereby',\n",
    "                     'thered', 'therefore', 'therein', 'thereof', 'therere', 'theres', 'thereto', 'thereupon', 'these',\n",
    "                     'they',\n",
    "                     \"they'd\", \"they'll\", \"they're\", \"they've\", 'theyd', 'theyre', 'thing', 'things', 'think', 'thinks',\n",
    "                     'third', 'this', 'thorough', 'thoroughly', 'those', 'thou', 'though', 'thoughh', 'thought',\n",
    "                     'thoughts',\n",
    "                     'thousand', 'three', 'throug', 'through', 'throughout', 'thru', 'thus', 'til', 'tip', 'to',\n",
    "                     'today',\n",
    "                     'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'ts',\n",
    "                     'turn',\n",
    "                     'turned', 'turning', 'turns', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless',\n",
    "                     'unlike',\n",
    "                     'unlikely', 'until', 'unto', 'up', 'upon', 'ups', 'us', 'use', 'used', 'useful', 'usefully',\n",
    "                     'usefulness',\n",
    "                     'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vol', 'vols',\n",
    "                     'vs',\n",
    "                     'w', 'want', 'wanted', 'wanting', 'wants', 'was', \"wasn't\", 'wasnt', 'way', 'ways', 'we', \"we'd\",\n",
    "                     \"we'll\",\n",
    "                     \"we're\", \"we've\", 'wed', 'welcome', 'well', 'wells', 'went', 'were', \"weren't\", 'werent', 'what',\n",
    "                     \"what'll\", \"what's\", 'whatever', 'whats', 'when', 'whence', 'whenever', 'where', \"where's\",\n",
    "                     'whereafter',\n",
    "                     'whereas', 'whereby', 'wherein', 'wheres', 'whereupon', 'wherever', 'whether', 'which', 'while',\n",
    "                     'whim',\n",
    "                     'whither', 'who', \"who'll\", \"who's\", 'whod', 'whoever', 'whole', 'whom', 'whomever', 'whos',\n",
    "                     'whose',\n",
    "                     'why', 'widely', 'will', 'willing', 'wish', 'with', 'within', 'without', \"won't\", 'wonder', 'wont',\n",
    "                     'words', 'work', 'worked', 'working', 'works', 'world', 'would', \"wouldn't\", 'wouldnt', 'www', 'x',\n",
    "                     'y',\n",
    "                     'year', 'years', 'yes', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'youd', 'young',\n",
    "                     'younger',\n",
    "                     'youngest', 'your', 'youre', 'yours', 'yourself', 'yourselves', 'z', 'zero', 'zerowhose', '’', '“',\n",
    "                     '”',\n",
    "                     'will', 'thing', \"n't\", \"''\", \"'s\", '``', \"'re\", \"'\", 'mr', 'mr.', '--', '...', '..', '->', \"'.\",\n",
    "                     \"' '\",\n",
    "                     ' .', '’', '“', '”', '', '\\n']\n",
    "\n",
    "        # TODO: Get more complete list and read it from file\n",
    "        MORESTOP = ['will', 'thing', 'n\\'t', '\\'\\'', '\\'s', '``', '\\'re', '\\'', 'mr', 'mr.', '--', '...', '..', '->', '\\'.',\n",
    "                    '\\' \\'', ' .', '’',\n",
    "                    '“', '”', \"\", \"\\n\"]\n",
    "        for m in MORESTOP:\n",
    "            self.STOPWORDS.append(m)\n",
    "\n",
    "    def substitute_contractions(self, text):\n",
    "        \"\"\"\n",
    "        Loop through words and sub contractions\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        subbed = []\n",
    "        for word in text.split():\n",
    "            subbed.append(substitute_contraction(word))\n",
    "        return \" \".join(subbed)\n",
    "\n",
    "    def get_non_stopwords(self, text, substitute_contractions=True, stem=True):\n",
    "        \"\"\"\n",
    "        Returns a list of lowercase non-stopwords in the text.\n",
    "        non-stopwords are anything that is not punctuation or stopwords\n",
    "        Numerical values are NOT FILTERED OUT\n",
    "        :param text:\n",
    "        :param stem:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if substitute_contractions:\n",
    "            subbed_text = self.substitute_contractions(text)\n",
    "        else:\n",
    "            subbed_text = text\n",
    "\n",
    "        non_stop_words = []\n",
    "        tokens = word_tokenize(subbed_text)\n",
    "\n",
    "        # Loop through tokens\n",
    "        for tok in tokens:\n",
    "            t = tok.lower()\n",
    "            token = self.remove_punctuation(t)\n",
    "            if token not in self.STOPWORDS:\n",
    "                # Check if token contains punctuation\n",
    "                if token not in self.punctuation_list:\n",
    "                    if stem:\n",
    "                        non_stop_words.append(self.get_word_lemma(token))\n",
    "                    else:\n",
    "                        non_stop_words.append(token)\n",
    "\n",
    "        return non_stop_words\n",
    "\n",
    "    def get_noun_phrases(self, text, filter_stopwords=True):\n",
    "        \"\"\"\n",
    "        Gets the noun phrases from a text, by parsing grammar POS tagged\n",
    "        :param text:\n",
    "        :param filter_stopwords\"\n",
    "            Filters the stopwords from noun-phrases\n",
    "        :return:\n",
    "            Returns a list of noun phrases with list for each scentence\n",
    "        \"\"\"\n",
    "\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "        sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "\n",
    "        grammar = \"\"\"NP: {<DT>?<JJ>*<NN.*>+}\n",
    "                  \"\"\"\n",
    "\n",
    "        # Alternative grammer structures that can be parsed, can add to the grammar string\n",
    "        \"\"\"\n",
    "        RELATION: {<V.*>}\n",
    "                  {<DT>?<JJ>*<NN.*>+}\n",
    "        ENTITY: {<NN.*>}\n",
    "        \"\"\"\n",
    "\n",
    "        cp = nltk.RegexpParser(grammar)\n",
    "        noun_phrases_list = [[' '.join(leaf[0] for leaf in tree.leaves())\n",
    "                              for tree in cp.parse(sent).subtrees()\n",
    "                              if tree.label() == 'NP']\n",
    "                             for sent in sentences]\n",
    "\n",
    "        if not filter_stopwords:\n",
    "            return noun_phrases_list\n",
    "\n",
    "        # Filters the stopwords from the parsed noun phrases\n",
    "        else:\n",
    "            phrases = []\n",
    "            for elem in noun_phrases_list:\n",
    "                for noun_phrase in elem:\n",
    "\n",
    "                    # Search each word in return phrase to remove stopwords\n",
    "                    phrase = []\n",
    "                    for word in noun_phrase.split():\n",
    "                        w = word.lower()\n",
    "                        if w not in self.STOPWORDS:\n",
    "                            phrase.append(w)\n",
    "\n",
    "                    if phrase != []:\n",
    "                        phrases.append(\" \".join(phrase))\n",
    "\n",
    "            return phrases\n",
    "\n",
    "    # TODO: Improve parsing speed with spacy\n",
    "    def get_adjectives_list(self, text):\n",
    "        \"\"\"\n",
    "        Uses the POS tagger to get all of the Adjectives, whose tags start with \"j\"\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "        adjectives = []\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        for t in tagged:\n",
    "            # Check the first charcter if tag\n",
    "            if t[1][0] == \"J\":\n",
    "                adjectives.append(t[0])\n",
    "\n",
    "        return adjectives\n",
    "\n",
    "    # TODO: Improve parsing speed with spacy\n",
    "    def get_nouns_list(self, text):\n",
    "        \"\"\"\n",
    "        Uses the POS tagger to get all of the Adjectives, whose tags start with \"j\"\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "        nouns = []\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        for t in tagged:\n",
    "            # Check the first charcter if tag\n",
    "            if t[1][0] == \"N\":\n",
    "                nouns.append(t[0])\n",
    "\n",
    "        return nouns\n",
    "\n",
    "    def get_word_lemma(self, word):\n",
    "        \"\"\"\n",
    "        Helper to allows customization to stemming process, like checking for trailing e's\n",
    "        :param word:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        lema = self.lemmatizer.lemmatize(word)\n",
    "        return lema\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        \"\"\"\n",
    "        Helper function to remove all non-acsii charcters\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return ''.join([i if ord(i) < 128 else '' for i in text])\n",
    "\n",
    "    def is_text_token(self, token):\n",
    "        \"\"\"\n",
    "        Checks if not punc or numerical, or non-acsii\n",
    "        :param token:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if len(token) == 1:\n",
    "            if ord(token) < 128 and token not in punctuation and not token.isdigit():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            if not token.isdigit():\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "class SummaryException(Exception):\n",
    "    \"\"\"\n",
    "    If text could not meet summary requirments, lenght, content...\n",
    "    TODO: from summa import summarizer, summarizer performs well, graph based\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class Cleaner(LanguageProcessor):\n",
    "    \"\"\"\n",
    "    Freqeucy based summarizer\n",
    "    Summarizes to the min/max number of tokens required in summary\n",
    "    Use .summarize\n",
    "\n",
    "    Frequency based keyword list\n",
    "    Highest frequency noun_phrases\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, number_keywords=100):\n",
    "        \"\"\"\n",
    "\n",
    "        :param text:\n",
    "        :param title:\n",
    "        :param include_intro:\n",
    "            How many intro sentences to include in summary\n",
    "        \"\"\"\n",
    "\n",
    "        LanguageProcessor.__init__(self)\n",
    "\n",
    "        # Min/Max tokens in summary\n",
    "        self.minimum_length = 0\n",
    "        self.maximum_length = 1000\n",
    "        \n",
    "        self.minimum_tokens = 50\n",
    "\n",
    "        # Tokens that indicate sentence should not be in summary\n",
    "        self.non_body_sentence_blacklist = [\"Twitter\\n\", \"Facebook\\n\", \"Instagram\\n\", \"Getty Images\", \"\\n\"]\n",
    "\n",
    "        self.text = text\n",
    "        \n",
    "        self.number_keywords = number_keywords\n",
    "\n",
    "        # All non-stopwords tokens\n",
    "        self.tokens = []\n",
    "\n",
    "        # All non-stopwords tokens\n",
    "        self.noun_phrases = []\n",
    "\n",
    "        # Dict of scentences and tokens\n",
    "        self.sentence_dict = {}\n",
    "\n",
    "        # The intro sentences\n",
    "        self.intro = []\n",
    "        self.summarized_body = []\n",
    "\n",
    "        # Used for frequency based methods\n",
    "        self.tokens_freq = FreqDist()\n",
    "        self.noun_phrase_freq = FreqDist()\n",
    "\n",
    "        # Must parse first\n",
    "        self.parsed = False\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "        Performs NLP methods\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.refined_text_dict()\n",
    "        self.all_tokens()\n",
    "        self.all_noun_phrases()\n",
    "\n",
    "        # Used for frequency based methods\n",
    "        self.tokens_freq = FreqDist(self.tokens)\n",
    "\n",
    "        self.noun_phrase_freq = FreqDist(self.noun_phrases)\n",
    "\n",
    "        # Saves the intro sentences, and removes from dict\n",
    "\n",
    "        self.parsed = True\n",
    "\n",
    "    def keywords(self):\n",
    "        \"\"\"\n",
    "        Gets tokens from freqeucny distribution\n",
    "        :param number_keywords:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.parsed:\n",
    "            raise SummaryException(\"Must call summarize first!\")\n",
    "\n",
    "        keys = self.tokens_freq.most_common()\n",
    "\n",
    "        # Loop to just get keywords not the counts\n",
    "        keywords_list = []\n",
    "        for word in keys:\n",
    "            keywords_list.append(word[0])\n",
    "\n",
    "        return keywords_list[:500]\n",
    "\n",
    "    def key_noun_phrases(self, number_noun_phrases=5):\n",
    "        \"\"\"\n",
    "        Gets tokens from freqeucny distribution\n",
    "        :param number_noun_phrases:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.parsed:\n",
    "            raise SummaryException(\"Must call summarize first!\")\n",
    "\n",
    "        keys = self.noun_phrase_freq.most_common()\n",
    "\n",
    "        # Loop to just get keywords not the counts\n",
    "        noun_phrases_list = []\n",
    "        for word in keys:\n",
    "            noun_phrases_list.append(word[0])\n",
    "\n",
    "        return noun_phrases_list\n",
    "\n",
    "    def refined_text_dict(self, stem=True):\n",
    "        \"\"\"\n",
    "        Creates a dict of the scentences and the processed tokens in the sentences\n",
    "        Removes stopwords and can stem\n",
    "        :return:\n",
    "            Sets a dict of tokens of the sentences and tokens\n",
    "        \"\"\"\n",
    "\n",
    "        sentence_tokenized = sent_tokenize(self.text)\n",
    "\n",
    "        # Initilize dict from keys, with [ ] as initial value\n",
    "        scentence_dict = dict([(key, []) for key in sentence_tokenized])\n",
    "\n",
    "        all_tokens = []\n",
    "\n",
    "        # Simple loop to tokenize and add words to the sent dict, hashed by the words in sent\n",
    "        for sent in sentence_tokenized:\n",
    "            tokens = self.get_non_stopwords(sent, stem=stem)\n",
    "            scentence_dict[sent] = tokens\n",
    "\n",
    "        # Returns all tokens, used for Freq Distribution\n",
    "        for scentence, scentence_tokens in scentence_dict.items():\n",
    "            for tok in scentence_tokens:\n",
    "                all_tokens.append(tok)\n",
    "\n",
    "\n",
    "        self.sentence_dict = scentence_dict\n",
    "\n",
    "    def all_tokens(self):\n",
    "\n",
    "        # Get all tokens\n",
    "        for scentence, scentence_tokens in self.sentence_dict.items():\n",
    "            for tok in scentence_tokens:\n",
    "                if self.is_text_token(tok):\n",
    "                    self.tokens.append(tok)\n",
    "                    \n",
    "#         if len(self.tokens) < self.number_keywords:\n",
    "#             raise SummaryException(\"Not enough text to summarize!\")\n",
    "\n",
    "    def all_noun_phrases(self):\n",
    "\n",
    "        # Get noun phrases, ensure length greater than 1\n",
    "        noun_phrases = self.get_noun_phrases(self.text)\n",
    "        self.noun_phrases = [phrase for phrase in noun_phrases if len(phrase.split()) > 1]\n",
    "\n",
    "\n",
    "def text_cleaning_for_embeding(text):\n",
    "  \"\"\"\n",
    "  Formate the text for the document embedding\n",
    "  :param x:\n",
    "  :return:\n",
    "  \"\"\"\n",
    "\n",
    "  text_cleaner = Cleaner(text, number_keywords=50)\n",
    "  tokens = []\n",
    "\n",
    "  try:\n",
    "    text_cleaner.clean()\n",
    "    keyword = text_cleaner.keywords()\n",
    "    phrases = text_cleaner.key_noun_phrases(number_noun_phrases=10)\n",
    "    phrases = [phrase.replace(\" \", \"_\") for phrase in phrases]\n",
    "\n",
    "    tokens = keyword + phrases\n",
    "  except SummaryException:\n",
    "    pass\n",
    "\n",
    "  return tokens\n",
    "\n",
    "\n",
    "# Transform data to 'TaggedDocument'\n",
    "docs_train = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "print(\"Preprocessing Text\")\n",
    "for i, text in enumerate(article_list):\n",
    "    if len(text.split()) > 250:\n",
    "      \n",
    "      try:\n",
    "        processed_text = text_cleaning_for_embeding(text)\n",
    "        # register as namedtuple: analyzedDocument\n",
    "        tags = [i]\n",
    "\n",
    "        #     if len(processed_text) > 0:\n",
    "        docs_train.append(analyzedDocument(processed_text, tags))\n",
    "      except TypeError:\n",
    "        pass\n",
    "      \n",
    "print(\"Total cleaned: {0}\".format(len(docs_train)))\n",
    "\n",
    "print(\"Train gensim\")\n",
    "# dm=0 turns of the distibuted memory varient, just try to predict which words from which paragraph\n",
    "model = gensim.models.Doc2Vec(dm=0, vector_size=250, window=10, min_count=2, workers=8, alpha=0.025, epochs=35)\n",
    "\n",
    "# sample=1e-4, negative=5,\n",
    "# shuffling is better (ot needed at each trianing epoch\n",
    "shuffle(docs_train)\n",
    "# Build vocabulary from a sequence of sentences\n",
    "model.build_vocab(docs_train)\n",
    "# Update the model’s neural weights from a sequence of sentences\n",
    "\n",
    "print(\"Save gensim\")\n",
    "model.train(docs_train, epochs=model.epochs, total_examples=model.corpus_count)\n",
    "\n",
    "with open(save_file, 'wb') as handle:\n",
    "    pickle.dump(model, handle)\n",
    "\n",
    "# testing on training sentences:\n",
    "for i in range(0, 50):\n",
    "    t = docs_train[i].tags[0]\n",
    "    new_vector = model.infer_vector(docs_train[i].words, steps=50, alpha=0.025)\n",
    "    sims = model.docvecs.most_similar(\n",
    "        positive=[new_vector])  # gives you top 10 document tags and their cosine similarity\n",
    "    print(sims)\n",
    "\n",
    "    # model.docvecs.most_similar(): get similarity between word vector\n",
    "    # model.most_similar(): get similarity between document\n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    print('------------- %s' % article_list[t].split()[:50])\n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    for t, sim in sims:\n",
    "        print('\\n', sim, article_list[t].split()[:50])\n",
    "        \n",
    "        \n",
    "        \n",
    "import json\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=False, keep_inference=True)\n",
    "with open(save_file, 'wb') as handle:\n",
    "    pickle.dump(model, handle)\n",
    "handle.close()\n",
    "    \n",
    "import os\n",
    "os.path.getsize(save_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucTWimC4iSrg"
   },
   "source": [
    "Doc2Vec using full tokenized text stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_to_drive(\"health_doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WkOm51TjiSKw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re as re\n",
    "import gensim\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "random.seed(9001)\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import pickle\n",
    "\n",
    "file = \"all_articles.json\"\n",
    "save_file = \"my_doc2vec_model\"\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "content = []\n",
    "\n",
    "import json\n",
    "with open(file) as f:\n",
    "    content = json.load(f)\n",
    "    \n",
    "li_doc = [con[\"text\"] for con in content]\n",
    "\n",
    "print(\"Train doc {0}\".format(len(li_doc)))\n",
    "\n",
    "\n",
    "def text_cleaning_for_embeding(x):\n",
    "    #remove ponctuation\n",
    "    x = ' '.join(re.split('[?.,:/>!;]', x))\n",
    "    #remove entre parenthèse\n",
    "    x = x.replace('(','')\n",
    "    x = x.replace(')','')\n",
    "    #remove digits\n",
    "    x = ''.join([l.lower() for l in x if not l.isdigit()])\n",
    "    #remove stopwords and tokenize\n",
    "    x = ' '.join([w for w in x.split() if w not in cachedStopWords])\n",
    "    return(x)\n",
    "\n",
    "#Transform data to 'TaggedDocument'\n",
    "docs = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "for i, text in enumerate(li_doc):\n",
    "    text_ = text_cleaning_for_embeding(text)\n",
    "    #list of words\n",
    "    words = text_.split()\n",
    "    #small cleaning\n",
    "    words = [i.lower().strip() for i in words]\n",
    "    #register as namedtuple: analyzedDocument\n",
    "    tags = [i]\n",
    "    docs.append(analyzedDocument(words, tags))\n",
    "\n",
    "docs_train = docs[:2000]\n",
    "print(len(docs_train))\n",
    "# docs_test = docs[500:len(docs)]\n",
    "\n",
    "print(\"Train gensim\")\n",
    "model = gensim.models.Doc2Vec(dm=0, vector_size=100, window=10, min_count=1, workers=8, alpha=0.025, min_alpha=0.015, \n",
    "                              epochs=20)\n",
    "#sample=1e-4, negative=5,\n",
    "#shuffling is better (ot needed at each trianing epoch\n",
    "shuffle(docs_train)\n",
    "#Build vocabulary from a sequence of sentences \n",
    "model.build_vocab(docs_train)\n",
    "#Update the model’s neural weights from a sequence of sentences\n",
    "\n",
    "print(\"Train gensim\")\n",
    "with open(save_file, 'wb') as handle:\n",
    "  pickle.dump(model, handle)\n",
    "model.train(docs_train, epochs=model.epochs, total_examples=model.corpus_count)\n",
    "with open(save_file, 'wb') as handle:\n",
    "  pickle.dump(model, handle)\n",
    "\n",
    "#testing on 2 training sentences:\n",
    "for i in range(0,50):\n",
    "    t = docs_train[i].tags[0]\n",
    "    new_vector = model.infer_vector(docs_train[i].words[:125],steps=50, alpha=0.025)\n",
    "    sims = model.docvecs.most_similar(positive=[new_vector]) #gives you top 10 document tags and their cosine similarity\n",
    "    print(sims)\n",
    "    \n",
    "    #model.docvecs.most_similar(): get similarity between word vector\n",
    "    #model.most_similar(): get similarity between document\n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    print('------------- %s'%li_doc[t].split()[:20])\n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    for t,sim in sims:\n",
    "        print('\\n', sim, li_doc[t].split()[:20])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Doc2Vec Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
